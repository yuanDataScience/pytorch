{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8afbacb1",
   "metadata": {},
   "source": [
    "## Pytorch notes\n",
    "\n",
    "### What is pytorch\n",
    "* [pytorch link](pytorch.org) for most useful documents and examples\n",
    "* most popular research deep learning framework\n",
    "* write fast deep learning code in Python (able to run on a GPU/many GUPs)\n",
    "* Able to access many pre-built deep learning models (Torch hub/torchvision.models)\n",
    "* whole stack: preprocess data, model data, deploy model in your application/cloud\n",
    "* originally desinged and used in-house by Facebook/Meta (now open-source and used by companies such as Tesla, MIcrosoft, OpenAI)\n",
    "* find the [comnparison of deep learning frameworks from paperswithcode](paperswithcode.com/trends)\n",
    "  + browse state-of-the-art lists the workbench of deep learning applications/packages \n",
    "* allows you to work with GPU through an interface called Cuda \n",
    "\n",
    "* colab.research.google.com\n",
    "  + switch to GPU from Runtime tab\n",
    "  + check what GPU you are using by !nvidia-sml\n",
    "  \n",
    "### Pytorch pracitce \n",
    "* PyTorch Fuondamentals practice. [code is from the follwoing link](https://www.learnpytorch.io/00_pytorch_fundamentals/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0875ec6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (0.15.2)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (2.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.8.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.2.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: requests in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (from torchvision) (9.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (from requests->torchvision) (2022.5.18.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\huangy07\\appdata\\roaming\\python\\python310\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# install pytorch without CUDA\n",
    "! pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90b2bdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cpu'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebc2b9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.24.1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure numpy version is 1.24.1 (> 1.22 version)\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f85b2a",
   "metadata": {},
   "source": [
    "### Create scalar, vector, matrix and multiple dimensional tensor\n",
    "* A torch.Tensor is a multi-dimensional matrix containing elements of a single data type\n",
    "* A tensor can be constructed from a python list or sequence using torch.tensor() constructor\n",
    "  + torch.tensor() always copies data\n",
    "  + if you have a numpy array and want to avoid a copy, use `torch.as_tensor()`\n",
    "* A tensor of specific data type can be constructed by passing a torch.dtype and/or a torch.device to a constructor or tensor creation op\n",
    "    ```python\n",
    "        # create zeros of shape (2, 4) as integers\n",
    "        torch.zeros([2, 4], dtype=torch.int32)\n",
    "\n",
    "        # create cuda float64 tensor of shape (2,4)\n",
    "        cuda0 = torch.device('cuda:0')\n",
    "        torch.ones([2, 4], dtype=torch.float64, device=cuda0)\n",
    "    ```       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e00b890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalar=7\n",
      "vector=tensor([7, 7])\n",
      "MATRIX = tensor([[7, 7],\n",
      "        [8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# create tensor variables\n",
    "\n",
    "# scalar\n",
    "scalar = torch.tensor(7)\n",
    "print(f'scalar={scalar}')\n",
    "\n",
    "# vector\n",
    "vector = torch.tensor([7, 7])\n",
    "print(f'vector={vector}')\n",
    "\n",
    "# MATRIX\n",
    "MATRIX = torch.tensor([[7, 7], [8, 9]])\n",
    "print(f'MATRIX = {MATRIX}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a9702f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9081, 0.9764, 0.9223, 0.9591],\n",
      "        [0.1779, 0.7456, 0.1191, 0.8214],\n",
      "        [0.2575, 0.8997, 0.8899, 0.8312]]) torch.float32\n",
      "2\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# generate a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(size=(3, 4))\n",
    "print(random_tensor, random_tensor.dtype)\n",
    "print(random_tensor.ndim)\n",
    "print(random_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18fe9965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 torch.Size([224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "# create 3d tensor\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
    "print(random_image_size_tensor.ndim, random_image_size_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecbcf79",
   "metadata": {},
   "source": [
    "#### Converting between torch.tensor and numpy array\n",
    "* tensor can be converted to numpy array by calling its numpy() method\n",
    "  + has to have numpy version >= 1.24.1\n",
    "* tensor can be created directly from numpy array by calling `from_numpy` method\n",
    "* once brideged/linked, the tensor and numpy array point to the same memory address\n",
    "  + changing one of them also changes the other\n",
    "* if you want tensor and numpy array to be independent to each other, re-assign the tensor or numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "985322dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before, mat_np = [[7 7]\n",
      " [8 9]]\n"
     ]
    }
   ],
   "source": [
    "# convert tensor to numpy array\n",
    "mat_np = MATRIX.numpy()\n",
    "print(f'before, mat_np = {mat_np}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d6e54fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after, mat_np = [[4 4]\n",
      " [8 9]]\n"
     ]
    }
   ],
   "source": [
    "# after modifying MATRIX, the corresponding numpy array is changed\n",
    "MATRIX[0] = torch.tensor([4, 4])\n",
    "print(f'after, mat_np = {mat_np}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b95c687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before, a=[1. 1. 1. 1. 1.], b=tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "after a=[2. 2. 2. 2. 2.], b=tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# create tensor from numpy array\n",
    "# after changing numpy array, tensor is changed\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(f'before, a={a}, b={b}')\n",
    "np.add(a, 1, out=a)\n",
    "print(f'after a={a}, b={b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcb0a6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 2. 2. 2. 2.] tensor([3., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# on the other direction, changing\n",
    "# tensor changes the numpy array\n",
    "b[0] = torch.tensor(3)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "88acc5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to keep tensor and numpy array independent from each other\n",
    "# reassign the tensor or numpy array when modifying them\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "32688554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change array, and reassign array \n",
    "# to make numpy array and tensor independent\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b67821a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([2., 3., 4., 5., 6., 7., 8.], dtype=torch.float64))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create numpy array from tensor by tensor.numpy\n",
    "# modify tensor and re-assign the modified tensor\n",
    "# to tensor to make array and tensor independent\n",
    "array1 = tensor.numpy()\n",
    "tensor = tensor + 1\n",
    "array1, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6e2b90",
   "metadata": {},
   "source": [
    "#### Create zeros and ones vectors and tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42b755ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d94bee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size=(3, 4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4767748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the numbers in a range, the same as python range\n",
    "torch.arange(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bec0a7",
   "metadata": {},
   "source": [
    "#### Data types\n",
    "* some data types are for CPU, others for GPU\n",
    "* torch.cuda means the tensor is used for GPU\n",
    "* most common types are torch.float32 and torch.float64/torch.double\n",
    "  + also torch.float16\n",
    "  \n",
    "* pytorch often likes tensors to be the same format\n",
    "* pytorch often likes tensors on the same device, rather than one on CPU and the other on GPU\n",
    "* you can get the information about the dtype, device and shape by calling the methods of tensor\n",
    "  + `some_tensor.shape`\n",
    "  + `some_tensor.dtype`\n",
    "  + `some_tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bd353a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99089b4d",
   "metadata": {},
   "source": [
    "### Basic operations\n",
    "* basic operations include\n",
    "  + addition\n",
    "  + subtraction\n",
    "  + multiplication\n",
    "* all basic operations are vectorized\n",
    "  + if you use the operators such as +, - and *, the results will not be stored, unless you rassign it to the original variables\n",
    "  + you can use tensor.add, torch.mul with the same effects as operators.\n",
    "  + operators are more commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79555061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tensor = tensor([1, 2, 3])\n",
      "addition, tensor+10 = tensor([11, 12, 13])\n",
      "subtraction, tensor-10 = tensor([-9, -8, -7])\n",
      "multiplication, tensor*10 = tensor([10, 20, 30])\n",
      "tensor after operations = tensor([1, 2, 3])\n",
      "torch.add(tensor, 10) = tensor([11, 12, 13])\n",
      "torch.multiply(tensor, 10) = tensor([10, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(f'original tensor = {tensor}')\n",
    "\n",
    "# addition\n",
    "print(f'addition, tensor+10 = {tensor + 10}')\n",
    "\n",
    "# subtraction\n",
    "print(f'subtraction, tensor-10 = {tensor - 10}')\n",
    "\n",
    "# multiplication\n",
    "print(f'multiplication, tensor*10 = {tensor * 10}')\n",
    "\n",
    "# all operations will not change original tensor\n",
    "print(f'tensor after operations = {tensor}')\n",
    "\n",
    "# use torch.add \n",
    "print(f'torch.add(tensor, 10) = {torch.add(tensor, 10)}')\n",
    "\n",
    "# use torch.multiply\n",
    "print(f'torch.multiply(tensor, 10) = {torch.multiply(tensor, 10)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d5fd5c",
   "metadata": {},
   "source": [
    "### Matrix multiplication\n",
    "* element wise multiplication of two tensors of identical size\n",
    "  + directly multiply the two tensors\n",
    "* matrix multiplication (inner dimensions must match)\n",
    "  + use torch.matmul\n",
    "  + can also use @, which is not recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72e79fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize tensor\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "952a4c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element-wise multiplication\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d400cf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48506d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# matmul is faster than matrix\n",
    "# multiplication by for loop\n",
    "\n",
    "value = 0\n",
    "for num in tensor:\n",
    "    value += num * num\n",
    "    \n",
    "value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b987576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c22d19",
   "metadata": {},
   "source": [
    "#### Matrix shape matching in matrix multiplications\n",
    "* tensor object has a property of .T, which is the transpose of tensor\n",
    "* torch.transpose(input, dim0, dim1) switches the dimensions of a give tensor\n",
    "* torch.nn.Linear() module, also known as a feed-forward layer or fully connected layer, implements a matrix multiplication between an input X and a weight matrix A.\n",
    "  + in pytorch, each sample occupies a row, so the number of features is the number of columns\n",
    "  + torch.nn.Linear specifies `in_features` and `out_features` as the number of features of input and output\n",
    "  + torch.nn.Linear generates randomly initialized weight matrix to transfer input to output using the randomly generated weight matrix with the specified featur dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a70ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_A = torch.tensor([[1, 2],[3, 4], [5, 6]], dtype=torch.float32)\n",
    "tensor_B = torch.tensor([[7, 8], [9, 10], [11, 12]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd51214b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.],\n",
      "        [ 9., 10.],\n",
      "        [11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# view tensor_A and tensor_B\n",
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b53e26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 23.,  29.,  35.],\n",
       "        [ 53.,  67.,  81.],\n",
       "        [ 83., 105., 127.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b8c3691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([3, 2])\n",
      "output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# use torch.nn.linear to generate fully\n",
    "# connected neuron network to tranform\n",
    "# input matrix to output matrix\n",
    "torch.manual_seed(42)\n",
    "\n",
    "linear = torch.nn.Linear(in_features=2, out_features=6)\n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "\n",
    "print(f'input shape: {x.shape}')\n",
    "print(f'output shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d8aa1",
   "metadata": {},
   "source": [
    "### Transformation of Tensors\n",
    "#### Aggregation of tensor\n",
    "* we can find the min, max, mean and sum of tensors using tensor's aggregation methods\n",
    "  + x.min()\n",
    "  + x.max()\n",
    "  + x.mean()\n",
    "  + x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "627df05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0f9b1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min is 0\n",
      "max is 90\n",
      "average is 45.0\n",
      "sum is 450\n"
     ]
    }
   ],
   "source": [
    "print(f\"min is {x.min()}\")\n",
    "print(f\"max is {x.max()}\")\n",
    "print(f\"average is {x.type(torch.float32).mean()}\")\n",
    "print(f\"sum is {x.sum()}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f3de9c",
   "metadata": {},
   "source": [
    "#### Change tensor datatype\n",
    "* A common issue with deep learning operations is having your tensors in different datatypes\n",
    "  + if one tensor is in torach.float64, and another is in torch.float32, you might run into some errors\n",
    "  + you can create tensor based on the current tensor with the desired datatype by tensor.type(dtype)\n",
    "    + the function will return a new tensor with the dtype using the original data content\n",
    "* Different datatypes\n",
    "  + the lower the number (e.g. 32, 16, 8), the less precise a computer stores the value\n",
    "  + a lower amount of storage generally results in faster computation and a smaller overall model\n",
    "  + mobile-based neural networks often operate with 8-bit integers, smaller and faster to run but less accurate than their float32 counterparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1f34427d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor and check its datatype\n",
    "tensor = torch.arange(10., 100., 10.)\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51e1ca37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a float16 tensor\n",
    "tensor_float16 = tensor.type(dtype=torch.float16)\n",
    "tensor_float16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f041a41",
   "metadata": {},
   "source": [
    "#### reshape, stacking, squeezing and unsqueezing\n",
    "* torch.reshape(input, shape). Can also use torch.Tensor.reshape()\n",
    "* torch.Tensor.view(shape)\n",
    "  + returns a view of the original tensor in a different shape but shares the same data as the original tensor\n",
    "* torch.stack(tensors, dim=0)\n",
    "  + concatenates a sequence of tensors along a new dimension(dim), all thensors must be same size\n",
    "* torch.squeeze(input)\n",
    "  + squeezes input to remove all the dimensions with value 1\n",
    "* torch.unsqueeze(input, dim)\n",
    "  + returns input with a dimension value of 1 added at dim\n",
    "* torch.permute(input, dims)\n",
    "  + returns a view of the original input with its dimension permuted (rearranged) to dims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2a66e0",
   "metadata": {},
   "source": [
    "#### Reshape code examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f81bcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor\n",
    "import torch\n",
    "\n",
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf984dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([[1., 2., 3., 4., 5., 6., 7.]]),\n",
       " torch.Size([1, 7]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape the tensor by adding an extra dimension\n",
    "x_reshaped = x.reshape(1, 7)\n",
    "x, x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34c96c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape(1,7) is the same as unsqueeze\n",
    "torch.unsqueeze(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e347cb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the view with torch.view\n",
    "z = x.view(1, 7)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "39d6e3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that view shares the same underline data with original tensor\n",
    "# if you change the view, the original tensor is changed, too\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "945d76f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can specify the element by indices to reset element\n",
    "z[0][0] = 1.\n",
    "z, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eb7b50",
   "metadata": {},
   "source": [
    "#### Stack code examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7de5ef3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([[1., 2., 3., 4., 5., 6., 7.],\n",
       "         [1., 2., 3., 4., 5., 6., 7.],\n",
       "         [1., 2., 3., 4., 5., 6., 7.],\n",
       "         [1., 2., 3., 4., 5., 6., 7.],\n",
       "         [1., 2., 3., 4., 5., 6., 7.]]),\n",
       " torch.Size([5, 7]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack tensors on top of each other\n",
    "# is done by setting dim = 0. This is\n",
    "# also called vertical stack\n",
    "x = torch.arange(1., 8.)\n",
    "x_stacked_v = torch.stack([x, x, x, x, x], dim = 0)\n",
    "x, x_stacked_v, x_stacked_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2acce36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([[1., 1., 1., 1., 1.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [3., 3., 3., 3., 3.],\n",
       "         [4., 4., 4., 4., 4.],\n",
       "         [5., 5., 5., 5., 5.],\n",
       "         [6., 6., 6., 6., 6.],\n",
       "         [7., 7., 7., 7., 7.]]),\n",
       " torch.Size([7, 5]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose the vector, and stack them\n",
    "# on horizontal direction\n",
    "x_stacked_h = torch.stack([x, x, x, x, x], dim = 1)\n",
    "x,x_stacked_h, x_stacked_h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078b4213",
   "metadata": {},
   "source": [
    "#### Squeeze and unsqueeze code example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5b33208d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1e40dc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(1, 7)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e8f477f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_squeezed = x_reshaped.squeeze()\n",
    "x_squeezed, x_squeezed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bd053a",
   "metadata": {},
   "source": [
    "#### Permute tensor's axis order\n",
    "* permute operation returns a view of the original tensor\n",
    "* if you change the values in the view, the original tensor will be changed accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7e819162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), torch.Size([3, 224, 224]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# permute the original tensor to rearrange the axis order\n",
    "# the current axis at 0, 1, 2 are changed to the original\n",
    "# axis at 2, 0, 1, corresponding to (3, 224, 224)\n",
    "x_permuted = x_original.permute(2, 0, 1)\n",
    "\n",
    "x_original.shape, x_permuted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f188529b",
   "metadata": {},
   "source": [
    "#### Indexing\n",
    "* this is used to select a portion/slice of data from a tensor\n",
    "* a key concept is that indexing values goes outer dimension -> inner dimension\n",
    "* you can use `:` to specify \"all values in this dimension\" and then use a comma to add another dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4f2971b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 2., 3.],\n",
       "          [4., 5., 6.],\n",
       "          [7., 8., 9.]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor with three dimensions \n",
    "x = torch.arange(1., 10.).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6f120ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First dimension:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "second dimension:\n",
      "tensor([1., 2., 3.])\n",
      "third dimension:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# index the first, second and third dimension\n",
    "# note the dimension is from outer to inner\n",
    "print(f'First dimension:\\n{x[0]}')\n",
    "print(f'second dimension:\\n{x[0][0]}')\n",
    "print(f'third dimension:\\n{x[0][0][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "de7d5303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate of : to select all\n",
    "\n",
    "# get all values of 0th dimension and the 0 index of 1st dimension\n",
    "# note that we only have one element in 0the dimension\n",
    "# this is the same as x[0, 0, :] since there is only one element\n",
    "# on the first dimension\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a1692b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 8.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all values of 0th and 1th dimensions but only index 1 of 2nd dimension\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "929737d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all values of 0th dimension but only 1 index value of the \n",
    "# 1st and 2nd dimensions\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b3953ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
    "x[0, 0, :] # same as x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642dd5b3",
   "metadata": {},
   "source": [
    "### Reproducibility\n",
    "* get the same results on different computers running the same code\n",
    "* fix the randomness by torch.manual_seed(seed=an integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8dba601b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# set random seed\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "# Have to reset the seed every time a new rand() is called\n",
    "# Otherwise, tensor_D will be different to tensor_C\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "# test if tensor_C == tensor_D\n",
    "random_tensor_C == random_tensor_D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fb8323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
